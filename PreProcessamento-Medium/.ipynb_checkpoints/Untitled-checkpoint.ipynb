{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47fdf7de-d98e-4e4b-bbd6-2beb709e299f",
   "metadata": {},
   "source": [
    "# Um guia completo para o pré-processamento de dados em machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c321f-e07c-4048-a725-d08a2f0d348d",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "A utilização de técnicas de inteligência artificial para resolver diversos problemas é um processo que em si possui inúmeros etapas que podem ser aplicadas em um ciclo a fim de chegarmos em um resultado satisfatório.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Dentro deste ciclo a etapa pré-processamento talvez seja a mais importante a fim de se obter um bom resultado, o pré-processamento nada mais é do que o processo de preparação, organização e estruturação dos nossos dados além de ser o momento ideal para escolhermos quais dados fazem sentido fazerem parte do nosso dataset.<br/>\n",
    "</p>\n",
    "    <p style='text-align: justify;'>\n",
    "A ideia deste artigo é ser um ponto de referência para técnicas de pré-processamento que possam ser aplicadas em qualquer tipo de dados que mais tarde serão utilizados em técnicas de classificação com machine learning.<br/>\n",
    "</p>\n",
    "        <p style='text-align: justify;'>\n",
    "Antes de colocarmos a mão na massa é importante ressaltar a importância desta fase, pois a qualidade dos seus dados pode influenciar diretamente no resultado do seu modelo, muitas das vezes acabamos pensando que o problema da nossa solução é o algoritmo usado para gerar o modelo, porém o grande vilão é o seu próprio conjunto de dados que podem possuir muitos atributos com valores faltantes, outliers e escalas de valores contradizentes e por fim nenhum modelo será capaz de trabalhar com esses dados e gerar resultados de qualidade. Tenha em mente:\n",
    "</p>\n",
    "<blockquote>\n",
    "A qualidade do resultado do seu modelo começa com a qualidade dos dados que você está “inputando” na etapa de treino!\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2599f217-0035-4322-b959-002321ed9bf3",
   "metadata": {},
   "source": [
    "**Importando os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46d6009d-c971-4375-98d2-7d455065dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f043c624-3593-4b43-9768-42a84b202cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cde8e23-c560-4c80-8e3b-a487d082e4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "      <th>sócio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diretor</td>\n",
       "      <td>45</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analista</td>\n",
       "      <td>22</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programador</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerente</td>\n",
       "      <td>24</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gerente</td>\n",
       "      <td>30</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cargo  idade  salario    bonus sócio\n",
       "0      Diretor     45  24000.0  10000.0   sim\n",
       "1     Analista     22   8000.0   2000.0   não\n",
       "2  Programador     30      NaN   1000.0   não\n",
       "3      Gerente     24  15100.0      NaN   não\n",
       "4      Gerente     30  35000.0   6000.0   sim"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2068dd1-6bc0-4738-9d5f-af553cacd05c",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "    Explicando um pouco melhor o nosso dataset, nós temos os dados de 13 funcionários de uma empresa e baseado no cargo, idade, salário e bônus o nosso modelo futuramente tentará nos dizer quem são os sócios desta empresa.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Agora que conhecemos melhor nossos dados a primeira coisa que devemos fazer é separar os dados em um conjunto de atributos que serão usados como variáveis de input: cargo, idade, salário e bônus e separar a variável resultante: sócio.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aed747a-6033-4aeb-b406-cf5e72c21bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values # cargo, idade, salário e bônus\n",
    "Y = dataset['sócio'].values # sócio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65930932-9b9a-46a4-b82c-799076b4b23a",
   "metadata": {},
   "source": [
    "**Tratando dados faltantes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ad9d1-9eb9-4331-80ab-1c9fa95493ab",
   "metadata": {},
   "source": [
    "* **1. Deletar as colunas com dados faltantes:**\n",
    "<p style='text-align: justify;'>Essa solução ao meu ver é bem drástica e somente deverá ser utilizada quando a variável não exercer uma certa influência no resultado procurado. Talvez seja esta a solução menos recomendada! Mas caso queira utilizá-la basta usar a função dropna pandas, utilizando como parâmetros o axis = 1 para dizer que queremos deletar a coluna e inplace = True para aplicarmos no dataset e não criarmos uma cópia deste:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e27ef47-c72f-4437-a631-bc73fda1d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2323e1-5f31-4398-b7f6-e8f733cbcb96",
   "metadata": {},
   "source": [
    "* **2. Deletar os exemplos com dados faltantes:**\n",
    "<p style='text-align: justify;'>Uma solução bem melhor para o problema porém ainda não é a ideal para um dataset no qual você possui poucos exemplos, para aplicar basta utilizarmos a função dropna do pandas com o axis = 0:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab1344f8-4f56-438f-865f-a0a771edab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df98d30-80c1-4bc3-932b-f2d61a1b93fe",
   "metadata": {},
   "source": [
    "* **3. Preencher os dados faltantes com a média dos valores do atributo:**\n",
    "<p style='text-align: justify;'>Essa é a minha solução favorita e que iremos utilizar nesse guia. Em nosso problema iremos fazer isso da forma mais simples, aplicando o valor da média das colunas salário e bônus nos exemplos que não possuem esse valor. Notem que se quiséssemos poderíamos ir um pouco mais afundo e calcular essas médias de acordo com o cargo para depois aplicarmos a média que mais faz sentido. Primeiro vamos voltar ao cabeçalho e importar a classe Imputer que irá nos auxiliar nessa tarefa:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8ed68b7-0bbe-48c5-8cd3-31e077438204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "      <th>sócio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diretor</td>\n",
       "      <td>45</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analista</td>\n",
       "      <td>22</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programador</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerente</td>\n",
       "      <td>24</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gerente</td>\n",
       "      <td>30</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Programador</td>\n",
       "      <td>22</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analista</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Diretor</td>\n",
       "      <td>50</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fundador</td>\n",
       "      <td>65</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analista</td>\n",
       "      <td>32</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Programador</td>\n",
       "      <td>35</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Programador</td>\n",
       "      <td>28</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fundador</td>\n",
       "      <td>28</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Programador</td>\n",
       "      <td>30</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cargo  idade  salario    bonus sócio\n",
       "0       Diretor     45  24000.0  10000.0   sim\n",
       "1      Analista     22   8000.0   2000.0   não\n",
       "2   Programador     30      NaN   1000.0   não\n",
       "3       Gerente     24  15100.0      NaN   não\n",
       "4       Gerente     30  35000.0   6000.0   sim\n",
       "5   Programador     22   5300.0   2000.0   não\n",
       "6      Analista     20      NaN   1200.0   não\n",
       "7       Diretor     50  18000.0   8000.0   sim\n",
       "8      Fundador     65  38000.0  28000.0   sim\n",
       "9      Analista     32   7300.0   4000.0   não\n",
       "10  Programador     35   2344.0      NaN   não\n",
       "11  Programador     28   4500.0   2200.0   não\n",
       "12     Fundador     28  30000.0  12000.0   sim\n",
       "13  Programador     30  14000.0  10000.0   sim"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15cde383-df7b-44ad-8ac9-c7ffb2895fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['salario'].fillna(dataset.groupby('cargo')['salario'].transform('median'), inplace=True)\n",
    "dataset['bonus'].fillna(dataset.groupby('cargo')['bonus'].transform('median'), inplace=True)\n",
    "\n",
    "X = dataset.iloc[:, :-1].values # cargo, idade, salário e bônus\n",
    "Y = dataset['sócio'].values # sócio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943411a-ea2e-4dd0-9e34-16fb80f993f1",
   "metadata": {},
   "source": [
    "* **4. Preencher os dados faltantes com o valor que você quiser:**\n",
    "<p style='text-align: justify;'>\n",
    "Com essa alternativa o céu é o limite e você poderá preencher os seus dados faltantes com o valor que melhor convier para o seu problema, para isto basta utilizar a função fillna do padas, alguns exemplos para o nosso problema seriam:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bda336e-a23a-4477-a4c0-7f1431181dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.fillna(0) #Preencher todos os valores faltantes por zero\n",
    "#Preencher cada coluna com o valor que melhor satisfazer:\n",
    "#values = {'salario': valor, 'bonus': valor}\n",
    "#dataset.fillna(value=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa44bf-6c32-4419-a27e-f4c0071a80f3",
   "metadata": {},
   "source": [
    "**Variáveis categóricas**\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Outro problema do nosso dataset são as variáveis categóricas que nesse caso se restringem apenas a coluna cargo, ou seja, uma variável categórica é uma variável nominal, sem escala, não numérica.\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Uma ideia para tratar esse problema é utilizar a classe LabelEncoder do sklearn para transformar os nomes em números (diretor: 0, analista: 1, gerente: 2, programador: 3 e fundador: 4) e por conseguinte transformar esse números em novas colunas do dataset com OneHotEncoder do sklearn, com objetivo de eliminar a hierarquia dos valores que não possuem muito significado para os cargos neste problema. Ou seja os cargos diretor, analista, gerente, programador e fundador seriam colunas do nossa dataset e cada funcionário receberá o valor 1 para o seu cargo na coluna e o valor 0 para os cargos que não ocupam.\n",
    "</p>\n",
    "<p style='text-align: justify;'>\n",
    "Vamos começar importando o LabelEncoder e o OneHotEncoder no cabeçalho:\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559512b-24be-40c1-9536-222ec602667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a662c9e-69d9-4937-90f1-3376928b1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_cargos = list(dataset['cargo'].sort_values().unique())\n",
    "colunas = []\n",
    "for i in valores_cargos:\n",
    "    colunas.append('cargo_' + i)\n",
    "colunas = colunas + ['idade', 'salario', 'bonus', 'sócio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00520928-3c5b-4d53-a1f5-9fbee7c9a900",
   "metadata": {},
   "source": [
    "Agora vamos criar um objeto do LabelEncoder e fazer fit_tranform apenas para a nossa coluna com valores categóricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cf988-987e-4fc3-b8a8-2d5ed477c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6b58a-51c5-42f5-9fd9-bc461b643eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = onehotencoder.fit_transform(dataset[['cargo']]).toarray()\n",
    "enc_df = pd.DataFrame(enc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d0df8-3841-411b-a930-a944df394c4d",
   "metadata": {},
   "source": [
    "Continuando podemos deixar nossa variável X como um array ou transformar novamente em um dataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac92223-4602-46ef-90af-98cfbea4e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = enc_df.join(dataset)\n",
    "dataset.drop('cargo', axis=1, inplace=True)\n",
    "dataset.columns = colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0c9ef-8ffb-4980-9d09-b614aab08ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b60e36-b045-4740-8d26-2aed03b6d1de",
   "metadata": {},
   "source": [
    "**Outra forma de fazermos essa transformação é com o próprio pandas com o método, get_dummies:**\n",
    "<br/>\n",
    "Primeiro vamos criar um dataFrame apenas com a coluna cargos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79a96a7a-8ca1-4825-ae0c-1ade52dfd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cargo = pd.DataFrame({'cargo':X[:,0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42542115-adca-4547-a895-5b988556898b",
   "metadata": {},
   "source": [
    "Agora vamos transformar o nosso dataFrame com uma coluna de variáveis categóricas em colunas que representam cada cargo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12e52e3c-6021-4513-aa2d-0f93022c5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cargo = pd.get_dummies(X_cargo)\n",
    "dataset = X_cargo.join(dataset)\n",
    "dataset.drop('cargo', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "856472fb-a7ed-456e-ac97-42e00d12251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1] # cargo, idade, salário e bônus\n",
    "Y = dataset['sócio'].values # sócio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa5301-eeb6-47ac-9465-1b64760f2fa2",
   "metadata": {},
   "source": [
    "Por conseguinte também vamos transformar a nossa variável Y (é sócio) em valores numéricos, onde sim será 1 e não será zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7d314e7-306d-451b-a4a5-c1f93ecd600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(Y)\n",
    "Y = Y['sim'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b0bba62-1091-45b3-b18e-65b9d5c9a28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4da1c-b65f-4d29-ac1e-e4d4859235ba",
   "metadata": {},
   "source": [
    "**Reescala dos dados**\n",
    "<p style='text-align: justify;'>\n",
    "Agora temos um novo problema, você pode observar que os valores das colunas idade, salário e bônus estão em uma escala bem distinta, onde a idade varia entre 20 a 65, salário varia entre 2344 a 38000 e bônus varia entre 1200 a 28000, e isto pode causar um grande problema no treino do nosso modelo uma vez o salário por possuir uma escala muito maior que a idade terá uma influência consequentemente muito maior no resultado e isto não é que nós queremos! Além disso podemos notar que as bordas representam alguns possíveis outliers os quais queremos minimizar o impacto em nossa solução. Para solucionar esses problemas poderíamos usar diversas técnicas de estatística e algumas métricas como quartis, desvio padrão e variância ou podemos ser muito mais espertos e já usar inúmeras ferramentas do sklearn que já aplicam todas essas técnicas a fim de obter uma melhor solução para o nosso problema através da reescala dos dados.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05cfe80-8d4e-4e8f-be30-642c073dd90a",
   "metadata": {},
   "source": [
    "**Normalizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a46f9-28cc-4c36-8518-9ce490d1e4a5",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Vamos começar com o Normalizer que talvez seja a solução mais diferente, uma vez que o Normalize age reescalando os dados por exemplos/linhas e não por colunas, ou seja, o Normalizer levará em contas os atributos idade, salário e bonus e reescalar os valores com base nesses três valores. O Normalizer é uma boa escolha quando você sabe que a distribuição dos seus dados não é normal/gaussiana ou quando você não sabe qual é o tipo de distribuição dos seus dados.\n",
    "   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "876c4d14-59be-45c1-aefc-0a727396688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93316464-a005-4db7-a621-911e4c3d4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize = X.copy()\n",
    "X_normalize[['idade', 'salario', 'bonus']] = Normalizer().fit_transform(X[['idade', 'salario', 'bonus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e02021f8-4fab-4a4a-8c82-350e39ec8b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo_Analista</th>\n",
       "      <th>cargo_Diretor</th>\n",
       "      <th>cargo_Fundador</th>\n",
       "      <th>cargo_Gerente</th>\n",
       "      <th>cargo_Programador</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.923076</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.970139</td>\n",
       "      <td>0.242535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.979786</td>\n",
       "      <td>0.199956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.929322</td>\n",
       "      <td>0.369267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.985622</td>\n",
       "      <td>0.168964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cargo_Analista  cargo_Diretor  cargo_Fundador  cargo_Gerente  \\\n",
       "0               0              1               0              0   \n",
       "1               1              0               0              0   \n",
       "2               0              0               0              0   \n",
       "3               0              0               0              1   \n",
       "4               0              0               0              1   \n",
       "\n",
       "   cargo_Programador     idade   salario     bonus  \n",
       "0                  0  0.001731  0.923076  0.384615  \n",
       "1                  0  0.002668  0.970139  0.242535  \n",
       "2                  1  0.005999  0.979786  0.199956  \n",
       "3                  0  0.001477  0.929322  0.369267  \n",
       "4                  0  0.000845  0.985622  0.168964  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalize.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbaa39b-4915-4010-9ba1-dae952967caf",
   "metadata": {},
   "source": [
    "**MinMaxScaler**\n",
    "<p style='text-align: justify;'>\n",
    "    O MinMaxScaler é uma outra alternativa a reescala de dados, seu diferencial se dá uma vez que este age sobre sobre a coluna, ou seja, o cálculo da reescala é feito de forma independente entre cada coluna, de tal forma que a nova escala se dará entre 0 e 1 (ou -1 e 1 se houver valores negativos no dataset). Importante ressaltar que essa técnica funciona melhor se a distribuição dos dados não for normal e se o desvio padrão for pequeno, além disso o MinMaxScaler não reduz de forma eficaz o impacto de outliers e também preserva a distribuição original. De forma simples o MinMaxScaler subtrai o valor em questão pelo menor valor da coluna e então divide pela diferença entre o valor máximo e mínimo:\n",
    "    </p>\n",
    "    \n",
    "> *valor = ( valor — Coluna.min) / (Coluna.max — Coluna.min)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f54c619-dd5d-4cd5-97fc-4235606dea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_minMax = X.copy()\n",
    "X_minMax[['idade', 'salario', 'bonus']] = MinMaxScaler().fit_transform(X[['idade', 'salario', 'bonus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "961198f2-5b47-47ed-b55b-748bd12bf68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo_Analista</th>\n",
       "      <th>cargo_Diretor</th>\n",
       "      <th>cargo_Fundador</th>\n",
       "      <th>cargo_Gerente</th>\n",
       "      <th>cargo_Programador</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.607359</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.158627</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.071685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.357752</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.915863</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cargo_Analista  cargo_Diretor  cargo_Fundador  cargo_Gerente  \\\n",
       "0               0              1               0              0   \n",
       "1               1              0               0              0   \n",
       "2               0              0               0              0   \n",
       "3               0              0               0              1   \n",
       "4               0              0               0              1   \n",
       "\n",
       "   cargo_Programador     idade   salario     bonus  \n",
       "0                  0  0.555556  0.607359  0.333333  \n",
       "1                  0  0.044444  0.158627  0.037037  \n",
       "2                  1  0.222222  0.071685  0.000000  \n",
       "3                  0  0.088889  0.357752  0.185185  \n",
       "4                  0  0.222222  0.915863  0.185185  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_minMax.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7037c4-89e7-4529-a4d2-8ce2b3e1733f",
   "metadata": {},
   "source": [
    "**StandardScaler**\n",
    "<p style='text-align: justify;'>\n",
    "Assim como o MinMaxScaler o StandardScaler age sobre as colunas, porém seu método é diferente uma vez que este subtrai do valor em questão a média da coluna e divide o resultado pelo desvio padrão. No final temos uma distribuição de dados com desvio padrão igual a 1 e variância de 1 também. Esse método trabalha melhor em dados com distribuição normal porém vale a tentativa para outros tipos de distribuições, além disso podemos deixar como dica que esse método resulta em ótimos frutos quando usado em conjunto com algoritmos como Linear Regression e Logistic Regression.\n",
    "</p>\n",
    "\n",
    "> valor = (valor — média) / desvioPadão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d473769-9351-439f-a26f-46b4a27ba7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_standard = X.copy()\n",
    "X_standard[['idade', 'salario', 'bonus']] = StandardScaler().fit_transform(X[['idade', 'salario', 'bonus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29505779-b526-4be6-9601-489f2963df76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo_Analista</th>\n",
       "      <th>cargo_Diretor</th>\n",
       "      <th>cargo_Fundador</th>\n",
       "      <th>cargo_Gerente</th>\n",
       "      <th>cargo_Programador</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002248</td>\n",
       "      <td>0.752892</td>\n",
       "      <td>0.472693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.907361</td>\n",
       "      <td>-0.630533</td>\n",
       "      <td>-0.690859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.243149</td>\n",
       "      <td>-0.898572</td>\n",
       "      <td>-0.836303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.741308</td>\n",
       "      <td>-0.016638</td>\n",
       "      <td>-0.109083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.243149</td>\n",
       "      <td>1.703997</td>\n",
       "      <td>-0.109083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cargo_Analista  cargo_Diretor  cargo_Fundador  cargo_Gerente  \\\n",
       "0               0              1               0              0   \n",
       "1               1              0               0              0   \n",
       "2               0              0               0              0   \n",
       "3               0              0               0              1   \n",
       "4               0              0               0              1   \n",
       "\n",
       "   cargo_Programador     idade   salario     bonus  \n",
       "0                  0  1.002248  0.752892  0.472693  \n",
       "1                  0 -0.907361 -0.630533 -0.690859  \n",
       "2                  1 -0.243149 -0.898572 -0.836303  \n",
       "3                  0 -0.741308 -0.016638 -0.109083  \n",
       "4                  0 -0.243149  1.703997 -0.109083  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standard.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a665cd4-bbb5-48e2-a369-6bcdd757fa99",
   "metadata": {},
   "source": [
    "**RobustScaler**\n",
    "<p style='text-align: justify;'>\n",
    "Também atua sobre as colunas e o diferencial deste método é a combinação com o uso de quartis o que nos garante um bom tratamento dos outliers. Em seu método o RobustScaler subtrai a média do valor em questão e então divide o resultado pelo segundo quartil. Importante notar que os outliers ainda estão presentes porém estão representados dentro de uma escala em que o seu impacto negativo é reduzido.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d1d7f23-cd7b-4dd4-9c05-dc1b39ac679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "X_robust = X.copy()\n",
    "X_robust[['idade', 'salario', 'bonus']] = RobustScaler().fit_transform(X[['idade', 'salario', 'bonus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9719f2a-24d8-4d43-8d61-a9db08df3b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo_Analista</th>\n",
       "      <th>cargo_Diretor</th>\n",
       "      <th>cargo_Fundador</th>\n",
       "      <th>cargo_Gerente</th>\n",
       "      <th>cargo_Programador</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.668896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.864865</td>\n",
       "      <td>-0.179641</td>\n",
       "      <td>-0.401338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.365269</td>\n",
       "      <td>-0.535117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.648649</td>\n",
       "      <td>0.245509</td>\n",
       "      <td>0.133779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.437126</td>\n",
       "      <td>0.133779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cargo_Analista  cargo_Diretor  cargo_Fundador  cargo_Gerente  \\\n",
       "0               0              1               0              0   \n",
       "1               1              0               0              0   \n",
       "2               0              0               0              0   \n",
       "3               0              0               0              1   \n",
       "4               0              0               0              1   \n",
       "\n",
       "   cargo_Programador     idade   salario     bonus  \n",
       "0                  0  1.621622  0.778443  0.668896  \n",
       "1                  0 -0.864865 -0.179641 -0.401338  \n",
       "2                  1  0.000000 -0.365269 -0.535117  \n",
       "3                  0 -0.648649  0.245509  0.133779  \n",
       "4                  0  0.000000  1.437126  0.133779  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_robust.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe97d28-141f-446f-9e1f-6d1e53198807",
   "metadata": {},
   "source": [
    "**QuantileTransformer**\n",
    "<p style='text-align: justify;'>\n",
    "Assim como o RobustScaler atua sobre as colunas e também trata os outliers com uso de quartis. Este método transforma os valores de tal forma que a distribuição tende a se aproximar de uma distribuição normal. Uma observação importante é que essa tranformação pode distorcer as correlações lineares entre as colunas. Neste método todos os valores serão reescalados em um intervalo de 0 a 1 de tal forma que os outliers não poderão mais ser distinguidos logo ao contrário do RobustScaler o impacto da ação em cima dos outilers será grande.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa42b9e4-a0ce-424d-ae41-96f4fd4793ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krupc\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2612: UserWarning: n_quantiles (1000) is greater than the total number of samples (14). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\"n_quantiles (%s) is greater than the total number \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "X_quantile = X.copy()\n",
    "X_quantile[['idade', 'salario', 'bonus']] = QuantileTransformer().fit_transform(X[['idade', 'salario', 'bonus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec7d4bef-47e0-42b3-a340-1897255bc973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo_Analista</th>\n",
       "      <th>cargo_Diretor</th>\n",
       "      <th>cargo_Fundador</th>\n",
       "      <th>cargo_Gerente</th>\n",
       "      <th>cargo_Programador</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cargo_Analista  cargo_Diretor  cargo_Fundador  cargo_Gerente  \\\n",
       "0               0              1               0              0   \n",
       "1               1              0               0              0   \n",
       "2               0              0               0              0   \n",
       "3               0              0               0              1   \n",
       "4               0              0               0              1   \n",
       "\n",
       "   cargo_Programador     idade   salario     bonus  \n",
       "0                  0  0.846154  0.769231  0.769231  \n",
       "1                  0  0.115385  0.461538  0.192308  \n",
       "2                  1  0.538462  0.153846  0.000000  \n",
       "3                  0  0.230769  0.615385  0.576923  \n",
       "4                  0  0.538462  0.923077  0.576923  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_quantile.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cd9f85-62a6-46fd-a1bb-e4a4c2806d25",
   "metadata": {},
   "source": [
    "**PowerTransformer**\n",
    "<p style='text-align: justify;'>\n",
    "Atua sobre as colunas e assim como o Quantile procura transformar os valores em uma distribuição mais normal, sendo indicado em situações onde uma distribuição normal é desejada para os dados, além disso esse método ainda suporta os métodos de transformação\n",
    "\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Box-Cox (dataset com dados positivos) e Yeo-Johnson (dataset com dados positivos e negativos).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac33505a-c4d9-42f5-83ca-4b58906d0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "X_power = X.copy()\n",
    "X_power[['idade', 'salario', 'bonus']] = PowerTransformer().fit_transform(X[['idade', 'salario', 'bonus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eefb7408-54bf-48c1-94de-afdbf6cd50f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cargo_Analista</th>\n",
       "      <th>cargo_Diretor</th>\n",
       "      <th>cargo_Fundador</th>\n",
       "      <th>cargo_Gerente</th>\n",
       "      <th>cargo_Programador</th>\n",
       "      <th>idade</th>\n",
       "      <th>salario</th>\n",
       "      <th>bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.187872</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.896997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.236273</td>\n",
       "      <td>-0.419139</td>\n",
       "      <td>-0.810813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053928</td>\n",
       "      <td>-0.989067</td>\n",
       "      <td>-1.634519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.828650</td>\n",
       "      <td>0.345613</td>\n",
       "      <td>0.384224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053928</td>\n",
       "      <td>1.404922</td>\n",
       "      <td>0.384224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cargo_Analista  cargo_Diretor  cargo_Fundador  cargo_Gerente  \\\n",
       "0               0              1               0              0   \n",
       "1               1              0               0              0   \n",
       "2               0              0               0              0   \n",
       "3               0              0               0              1   \n",
       "4               0              0               0              1   \n",
       "\n",
       "   cargo_Programador     idade   salario     bonus  \n",
       "0                  0  1.187872  0.922680  0.896997  \n",
       "1                  0 -1.236273 -0.419139 -0.810813  \n",
       "2                  1  0.053928 -0.989067 -1.634519  \n",
       "3                  0 -0.828650  0.345613  0.384224  \n",
       "4                  0  0.053928  1.404922  0.384224  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_power.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a928077-bb01-4fbf-a260-75621da57bb4",
   "metadata": {},
   "source": [
    "| *_Método_*         | *_Quando usar_*                                                                                                                 | *_Observações_*                                                                                |   |\n",
    "|----------------|-----------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|---|\n",
    "| **Normalizer**     | Quando a distribuição dos seus dados não é normal ou quando você não sabe qual é o tipo distriuição dos seus dados          | Atua sobre as linhas/exemplos e não sobre as colunas/atributos                             |   |\n",
    "| **MinMaxScaler**   | Quando a distribuição dos dados não for normal e se o devio padrão for pequeno                                              | Não reduz de forma eficaz o impacto de outliers e também preserva a distribuição original. |   |\n",
    "| **StandardScaler** | Quando os dados estão com distribuição normal ou quando é necessário transformar os valores em uma distribuição mais normal | É uma boa combinação com algoritmos de regressão linear ou logística.                      |   |\n",
    "| **RobustScaler** | Quando queremos reduzir o impacto de outliers | |\n",
    "| **QuantileTransformer** | Quando queremos reduzir o impacto de outliers | Trata os outliers de uma forma mais agressiva do que o RobustScaler |\n",
    "| **PowerTransformer** | Quando é necessário transformar os valores em uma distribuição mais normal | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d5e8e-682e-4cd5-96be-09dd4d470140",
   "metadata": {},
   "source": [
    "**Selecionando os melhores atributos**\n",
    "<p style='text-align: justify;'>\n",
    "Agora que temos nossos dados reescalados em alguns datasets podemos contar com muitas colunas/atributos para nos auxiliar na tarefa de predição, porém nem sempre todos esses atributos possuem informações relevantes e muita das vezes podem levar o modelo a ter um resultado inferior do que se tivéssemos usados apenas poucos atributos. Portanto um trabalho importante é selecionar os atributos que mais fazem sentido e agregam valor em nossa solução. Para isso podemos contar com o SelectKBest do sklearn, onde o K representa o número máximo de atributos que desejamos ter em nosso dataset a ser “inputado” em nossa etapa de treino, dado o K o SelectKBest trata de encontrar os K melhores atributos a serem usados. \n",
    "    </p>\n",
    "    <p style='text-align: justify;'>\n",
    "    Importante ressaltar que aqui não existe uma melhor maneira de se escolher o valor para K a solução é tentar com diferentes valores e compararmos os resultados. Uma observação importante é que o SelectKBest não suporta dados valores negativos, portanto todos os métodos de reescala que transformam os valores em um intervalo que possui negativos devem ser descartados caso você queira aplica-lo. Em nosso exemplo irei experimentar K = 6 pois possuímos 8 atributos e irei utilizar o método de reescala MinMaxScaler, sinta-se à vontade para experimentar qualquer valor de K e qualquer método de reescala! O método fit_transform já nos retorna os valores dos atributos mais importantes por tanto podemos passar a usar o retorno como o nosso novo X.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bad7fadf-c8af-4b16-ab65-eb1591b0daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b638e02d-2459-4ed7-8893-bbbbb76ee4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=6).fit_transform(X_minMax, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc0c8082-e1ac-4826-b571-34893aa26c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        , 0.55555556, 0.60735921,\n",
       "        0.33333333],\n",
       "       [1.        , 0.        , 0.        , 0.04444444, 0.15862688,\n",
       "        0.03703704],\n",
       "       [0.        , 0.        , 0.        , 0.22222222, 0.07168499,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.08888889, 0.35775185,\n",
       "        0.18518519],\n",
       "       [0.        , 0.        , 0.        , 0.22222222, 0.91586269,\n",
       "        0.18518519],\n",
       "       [0.        , 0.        , 0.        , 0.04444444, 0.0829033 ,\n",
       "        0.03703704],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.14881086,\n",
       "        0.00740741],\n",
       "       [0.        , 1.        , 0.        , 0.66666667, 0.43908459,\n",
       "        0.25925926],\n",
       "       [0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.26666667, 0.13899484,\n",
       "        0.11111111],\n",
       "       [0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.04074074],\n",
       "       [0.        , 0.        , 0.        , 0.17777778, 0.06046668,\n",
       "        0.04444444],\n",
       "       [0.        , 0.        , 1.        , 0.17777778, 0.77563383,\n",
       "        0.40740741],\n",
       "       [0.        , 0.        , 0.        , 0.22222222, 0.3269015 ,\n",
       "        0.33333333]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ebb23-7c34-4f24-bdf4-ea0a7fac3f14",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Outra forma de escolhermos os melhores atributos é utilizando o SelectFromModel também do sklearn, o diferencial do SelectFromModel se dá na forma como ele escolhe os melhores atributos, uma vez que esta escolha está atrelada a importância de um atributo para um dado modelo, além disso podemos definir um valor limite(threshold) a partir do qual passamos a considerar um atributo como importante. Em nosso exemplo irei atrelar SelectFromModel com o classificador ExtraTreesClassifier. Ainda sobre o valor limite(threshold), podemos passar alguns valores no SelectFromModel ou não(None), caso não seja passado nada o limite utilizado por padrão será 1e-5, também podemos passar uma string “median” onde a média da importância dos atributos será o limite ou ainda podemos passar qualquer valor que desejamos. Aqui irei optar por passar “median”.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1fb85fc6-fc6b-467b-9eea-bf4e8b73f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, Y)\n",
    "clf.feature_importances_ #Mostra a importância de cada atributo\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True, threshold='median')\n",
    "X_new = model.transform(X_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b53d2f82-fc4e-4e0d-b496-269c38ab35ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.55555556, 0.60735921, 0.33333333],\n",
       "       [0.        , 0.04444444, 0.15862688, 0.03703704],\n",
       "       [0.        , 0.22222222, 0.07168499, 0.        ],\n",
       "       [0.        , 0.08888889, 0.35775185, 0.18518519],\n",
       "       [0.        , 0.22222222, 0.91586269, 0.18518519],\n",
       "       [0.        , 0.04444444, 0.0829033 , 0.03703704],\n",
       "       [0.        , 0.        , 0.14881086, 0.00740741],\n",
       "       [1.        , 0.66666667, 0.43908459, 0.25925926],\n",
       "       [0.        , 1.        , 1.        , 1.        ],\n",
       "       [0.        , 0.26666667, 0.13899484, 0.11111111],\n",
       "       [0.        , 0.33333333, 0.        , 0.04074074],\n",
       "       [0.        , 0.17777778, 0.06046668, 0.04444444],\n",
       "       [0.        , 0.17777778, 0.77563383, 0.40740741],\n",
       "       [0.        , 0.22222222, 0.3269015 , 0.33333333]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d6f61-285a-4421-8452-b9142975c522",
   "metadata": {},
   "source": [
    "**PCA**\n",
    "<p style='text-align: justify;'>\n",
    "Por fim podemos aplicar a técnica PCA nos atributos escolhidos, de forma grossa o PCA nada mais é que uma técnica a qual transforma atributos com uma certa correlação em um único atributo. O PCA deve ser aplicado apenas em casos em que o seu dataset possui muitas colunas, realmente um número muito grande e o treino do seu modelo acaba por ser muito demorado ou inviável devido ao alto número de colunas, uma vez que o PCA é uma técnica na qual sempre haverá perda de informações. Em nosso exemplo o PCA será aplicado de forma meramente ilustrativa uma vez que não possuímos muitas colunas. O atributo n_components representa quantos atributos queremos deixar, outra ideia é utilizar o parâmetro n_components=’mle’ dado isto Minka’s MLE será utilizado para escolher a melhor dimensão a ser mantida no seu caso.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d07b6d6e-8a08-47ef-9dd7-cc069ad5ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components='mle')\n",
    "X_new = pca.fit_transform(X_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a3f7993-ebfd-4c43-9527-b53ddda34d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56594686, -0.11140966, -0.27806026,  0.81866815,  0.07221809,\n",
       "        -0.09098694,  0.03647628],\n",
       "       [-0.16862395,  0.91937388, -0.20169256, -0.14814111,  0.00713517,\n",
       "        -0.03682199,  0.01289656],\n",
       "       [-0.70761706, -0.38187914, -0.02832426, -0.02946212,  0.00517101,\n",
       "         0.03358353, -0.07462793],\n",
       "       [ 0.20458287,  0.18537138,  0.91965691,  0.08186643,  0.0076858 ,\n",
       "         0.21922472,  0.11109336],\n",
       "       [ 0.50815261,  0.07596283,  0.968441  ,  0.05702959, -0.08774663,\n",
       "        -0.18631897, -0.10929465],\n",
       "       [-0.73945234, -0.35105186,  0.01425354, -0.06016358,  0.11180716,\n",
       "        -0.03420121,  0.03680472],\n",
       "       [-0.19533823,  0.93651964, -0.18787321, -0.14864879,  0.04873745,\n",
       "        -0.0412833 ,  0.01264536],\n",
       "       [ 0.49214945, -0.09766509, -0.32205774,  0.85833945,  0.02638038,\n",
       "         0.08389488, -0.02924807],\n",
       "       [ 1.27329357, -0.54896748, -0.3685824 , -0.57129498, -0.3076907 ,\n",
       "         0.04750057,  0.01108667],\n",
       "       [-0.09211543,  0.85799795, -0.27139145, -0.12852498, -0.17202976,\n",
       "         0.04512032, -0.02681746],\n",
       "       [-0.69770262, -0.40446703, -0.07286417, -0.01550118, -0.08529368,\n",
       "         0.12398718, -0.07405875],\n",
       "       [-0.71075889, -0.3790823 , -0.0243393 , -0.04167198,  0.01852818,\n",
       "         0.0257612 , -0.01417786],\n",
       "       [ 0.74410506, -0.21693891, -0.11351528, -0.57032224,  0.47927255,\n",
       "         0.00198581, -0.01770846],\n",
       "       [-0.4766219 , -0.48376421, -0.03365081, -0.10217265, -0.12417502,\n",
       "        -0.19144581,  0.12493022]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cb2af-08fc-4f4b-9f61-af96e8150a10",
   "metadata": {},
   "source": [
    "**Separando os seus dados em um conjunto de treino e de teste**\n",
    "<p style='text-align: justify;'></p>\n",
    "Uma das boas práticas no desenvolvimento de modelos é separar o seu dataset um conjunto de treino para treinar o seu modelo e outro de teste para validar os resultados do seu modelo. Essa separação é crucial a fim de identificar se o seu modelo não está “decorando” os resultados ao invés de aprender, o famoso overfitting.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1693f9-aa97-4428-881f-dffaf1d38b40",
   "metadata": {},
   "source": [
    "Vamos começar com o método **Train Test Split** do sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b219d2-2aad-415a-ab20-8399b3917cd4",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Neste exemplo irei continuar utilizando os atributos da variável X reescalados com o MinMaxScaler. Aqui iremos separar em 4 subconjuntos, X_train com as variáveis de input para treino do modelo e Y_train com os resultados de predição para treino, ambos serão utilizados mais tarde no método fit do seu modelo, X_test com as variáveis de input para test e Y_test com os resultados da predição para testes, o X_test será utilizado no método predict do seu modelo e o Y_test será utilizado para comparar com resultado retornado do seu método predict. O parâmetro test_size serve para indicar que o nosso conjunto de teste terá um tamanho de 20% em relação ao tamanho do dataset e o parâmetro random_state nos permite garantir que a separação dos conjuntos de teste e treino será sempre o mesmo, com a “semente” de aleatoriedade “semeada” sempre no valor indicado.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbde8757-880a-45b8-a097-8795f72fb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_minMax, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c9a3a-67f8-402a-bbfb-d946b8568b6a",
   "metadata": {},
   "source": [
    "Outra forma de fazemos essa separação é com o **KFold** do sklearn<br/>\n",
    "<p style='text-align: justify;'>\n",
    "Esta é a minha forma favorita de separar o dataset, pois o KFold facilita que possamos separar o nosso conjunto de dadas em conjunto de treinos e teste K vezes (indicado no parâmetro n_splits) e portanto fazer o treino e validar os resultados para 3 conjuntos diferentes de treino e teste. Antes precisamos colocar a nossa variável X em um formato de array.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33d9396d-3867-4fbe-95f2-51467b290f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1 - TRAIN: [ 5  6  7  8  9 10 11 12 13] TEST: [0 1 2 3 4]\n",
      "K = 2 - TRAIN: [ 0  1  2  3  4 10 11 12 13] TEST: [5 6 7 8 9]\n",
      "K = 3 - TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11 12 13]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_minMax.values\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "time = 1\n",
    "for train_index, test_index in kf.split(X_new):\n",
    "    print(\"K = \" + str(time) +  \" - TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    time += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b68c1f-3709-4f20-a31a-640c1eee399a",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Para finalizarmos é importante termos em mente que é de extrema importância que saibamos explorar os parâmetros disponíveis de cada método e classe utilizados no processo de pré-processamento utilizando a documentação do Sklearn que é incrível! Alguns ajustes de parâmetros podem trazer grandes ganhos para a sua solução, porém apenas com testes será possível encontrar os melhores parâmetros pois cada dataset tem suas peculiaridades, assim como cada problema e sua solução!\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa61b0-d628-4172-a632-e60729fb7212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
